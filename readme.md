# ğŸ“„ Contextual Document Assistant

A lightweight **RAG-style (Retrieval Augmented Generation)** document assistant that allows you to **ask natural language questions about a PDF or text document** and get **grounded answers with page citations**, powered by **Sentence Transformers + Ollama (local LLM)**.

This tool is designed for **offline / local use**, avoids hallucinations using similarity thresholds, and automatically installs missing dependencies.

---

## âœ¨ Features

- ğŸ“š Supports **PDF** and **TXT** documents
- ğŸ” Semantic search using **MiniLM embeddings**
- ğŸ§  Answers generated by a **local Ollama LLM** (no cloud APIs)
- ğŸ“„ Page-aware answers with **source citations**
- ğŸš« Hallucination guard using similarity thresholds
- âš™ï¸ Auto-installs required Python dependencies
- ğŸ’» Simple CLI interface

---

## ğŸ—ï¸ Architecture Overview

```
Document (PDF/TXT)
   â†“
Text Extraction (PyPDF2)
   â†“
Chunking (overlap-aware)
   â†“
Embeddings (MiniLM)
   â†“
Similarity Search
   â†“
Context Injection
   â†“
Ollama LLM Answer
```

---

## ğŸ“¦ Requirements

### System Requirements

- Python **3.9+**
- **Ollama** installed and running locally
- At least **8 GB RAM** recommended

### Ollama Model

This project is configured to use:

```
model: gemma3:4b
```

You can pull it using:

```bash
ollama pull gemma3:4b
```

---

## ğŸ“¥ Installation

### 1ï¸âƒ£ Clone / Copy the Project

Place the script in a directory, for example:

```
Document_assistant.py
```

### 2ï¸âƒ£ (Optional but Recommended) Create Virtual Environment

```bash
python -m venv venv
venv\Scripts\activate   # Windows
# source venv/bin/activate  # Linux / Mac
```

### 3ï¸âƒ£ Run the Script

The dependencies are installed using a `requirements.txt` file, so you can install them first and then run the script:

```bash
pip install -r requirements.txt
python Document_assistant.py
```

---

## ğŸ”Œ Dependencies

All required libraries are listed in `requirements.txt`.

Install them using:

```bash
pip install -r requirements.txt
```bash
pip install PyPDF2 sentence-transformers torch numpy requests
```

---

## â–¶ï¸ Usage

### Step 1: Start Ollama

Make sure Ollama is running:

```bash
ollama serve
```

### Step 2: Run the Assistant

```bash
python Document_assistant.py
```

### Step 3: Load a Document

```text
Enter PDF path (or 'q'): my_document.pdf
```

Supported formats:

- `.pdf`
- `.txt`

---

### Step 4: Ask Questions

```text
Question: What is the main conclusion of the study?
```

Example output:

```text
>> The study concludes that customer retention increased significantly after personalization.

(Source Pages: 4, 5)
```

---

## ğŸ§  Special Behaviors

### ğŸ“„ Page Count Questions

The assistant directly answers questions like:

- "How many pages are there?"
- "Total number of pages?"

Example:

```text
This document has a total of 12 pages.
```

---

### ğŸš« Hallucination Protection

If the answer is **not present in the document**, the assistant responds with:

```text
I don't know. (The information does not appear to be in this document).
```

This is enforced using a **similarity threshold**.

---

## âš™ï¸ Configuration

You can tweak these parameters inside the script:

```python
self.chunk_size = 800
self.chunk_overlap = 100
self.similarity_threshold = 0.15
```

### Ollama Settings

```python
OLLAMA_API_URL = "http://localhost:11434/api/generate"
OLLAMA_MODEL = "gemma3:4b"
```

---

## â— Common Issues

### âŒ `Ollama is not running`

Solution:

```bash
ollama serve
```

---

### âŒ `Import could not be resolved`

Ensure:

- Correct Python interpreter selected in VS Code
- Dependencies installed in the active environment

---

## ğŸš€ Future Improvements

- Web UI (Streamlit / FastAPI)
- Multi-document support
- Metadata-aware retrieval
- Persistent vector storage (FAISS / Chroma)
- Streaming responses

---

## ğŸ“œ License

This project is intended for **educational and personal use**.

---

## ğŸ™Œ Acknowledgements

- [Sentence Transformers](https://www.sbert.net/)
- [Ollama](https://ollama.com/)
- PyPDF2

---

## ğŸ“¸ Sample Output

![Document Assistant Sample](Images/Document Assistant Sample Image.jpg)

---

Happy querying! ğŸ”ğŸ“„

